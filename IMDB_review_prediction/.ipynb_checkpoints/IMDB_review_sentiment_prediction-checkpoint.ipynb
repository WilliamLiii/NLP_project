{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB review sentiment prediction\n",
    "create a classification model to predict the labels of movie reviews.\n",
    "\n",
    "## objectives\n",
    "* read all text data\n",
    "* text preprocessing\n",
    "* text vectorization\n",
    "* train classification models\n",
    "* evaluation models\n",
    "* analysis most import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read all text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_folder):\n",
    "    text_lst = []\n",
    "    for file in os.listdir(data_folder):\n",
    "        if '.txt' in file:\n",
    "            with open(os.path.join(data_folder, file), 'r', encoding='utf-8') as f:\n",
    "                review = f.read()\n",
    "                text_lst.append(review)\n",
    "    return text_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg = read_data(r'D:\\Google Drive receive\\Datasets\\IMDB movie review data\\train\\neg')\n",
    "train_pos = read_data(r'D:\\Google Drive receive\\Datasets\\IMDB movie review data\\train\\pos')\n",
    "test_neg = read_data(r'D:\\Google Drive receive\\Datasets\\IMDB movie review data\\test\\neg')\n",
    "test_pos = read_data(r'D:\\Google Drive receive\\Datasets\\IMDB movie review data\\test\\neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_neg, np.zeros(len(train_neg)))) + list(zip(train_pos, np.ones(len(train_pos))))\n",
    "test_data = list(zip(test_neg, np.zeros(len(test_neg)))) + list(zip(test_pos, np.ones(len(test_pos))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data, columns=['review', 'label'])\n",
    "test_df = pd.DataFrame(test_data, columns=['review', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data frames\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = train_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>I remember seeing this movie a long time ago o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>In my knowledge, Largo winch was a famous Belg...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>Police Story is one of Jackie Chan's classic f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>The name (Frau) of the main character is the G...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>One of the best musicals ever made, this is an...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "24995  I remember seeing this movie a long time ago o...    0.0\n",
       "24996  In my knowledge, Largo winch was a famous Belg...    0.0\n",
       "24997  Police Story is one of Jackie Chan's classic f...    1.0\n",
       "24998  The name (Frau) of the main character is the G...    0.0\n",
       "24999  One of the best musicals ever made, this is an...    1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON-\n",
      "name\n",
      "be\n",
      "William\n"
     ]
    }
   ],
   "source": [
    "for word in nlp('My name is William'):\n",
    "    print(word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_lst = stopwords.words('english')\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \"\"\"\n",
    "    :param text: a string\n",
    "    :return: a string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercasing text\n",
    "    text = re.sub(r'[/(){}\\[\\]|@,;]', ' ', text) # replace by white space\n",
    "    text = re.sub(r'[^0-9a-z #+_]', '', text) # remove other special characters\n",
    "    text = \" \".join([str(word.lemma_) if word.lemma_ != '-PRON-' else str(word) \n",
    "                     for word in nlp(text)]) # lemmatize tokens\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords_lst]\n",
    "                   ) # remove stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw this ages ago when I was younger and could never remember the title, until one day I was scrolling through John Candy's film credits on IMDb and noticed an entry named \"Once Upon a Crime...\". Something rang a bell and I clicked on it, and after reading the plot summary it brought back a lot of memories.<br /><br />I've found it has aged pretty well despite the fact that it is not by any means a \"great\" comedy. It is, however, rather enjoyable and is a good riff on a Hitchcock formula of mistaken identity and worldwide thrills.<br /><br />The movie has a large cast of characters, amongst them an American couple who find a woman's dog while vacationing in Europe and decide to return it to her for a reward - only to find her dead body upon arrival. From there the plot gets crazier and sillier and they go on the run after the police think they are the killers.<br /><br />Kind of a mix between \"It's a Mad Mad Mad Mad World\" and a lighter Hitchcock feature, this was directed by Eugene Levy and he managed to get some of his good friends - such as John Candy - to star in it. The movie is mostly engaging due to its cast, and the ending has a funny little twist that isn't totally unpredictable but also is kind of unexpected.\n",
      "\n",
      "see age ago young could never remember title one day scroll john candys film credit imdb notice entry name upon crime something ring bell click read plot summary bring back lot memoriesbr br find age pretty well despite fact mean great comedy however rather enjoyable good riff hitchcock formula mistaken identity worldwide thrillsbr br movie large cast character amongst american couple find womans dog vacation europe decide return reward find dead body upon arrival plot get crazy silly go run police think killersbr br kind mix mad mad mad mad world light hitchcock feature direct eugene levy manage get good friend john candy star movie mostly engage due cast ending funny little twist totally unpredictable also kind unexpected\n"
     ]
    }
   ],
   "source": [
    "# test preprocess function\n",
    "print(train_df.iloc[0,0])\n",
    "print()\n",
    "print(text_preprocess(train_df.iloc[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text vecterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['review']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['review']\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words vectorization\n",
    "bow_cv = CountVectorizer(max_df=0.8, min_df=5, ngram_range=(1,2))\n",
    "X_train_bow = bow_cv.fit_transform(X_train)\n",
    "X_test_bow = bow_cv.transform(X_test)\n",
    "bow_cv_vocab = bow_cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf vectorization\n",
    "tfidf = TfidfVectorizer(max_df=0.8, min_df=5, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "tfidf_vocab = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of bow: 1.0\n",
      "score of tfidf: 0.95192\n"
     ]
    }
   ],
   "source": [
    "# train a logistic regression model\n",
    "logis_ml = LogisticRegression()\n",
    "logis_ml.fit(X_train_bow, y_train)\n",
    "y_pred_bow = logis_ml.predict(X_test_bow)\n",
    "print(f\"score of bow: {logis_ml.score(X_test_bow, y_test)}\")\n",
    "logis_ml.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = logis_ml.predict(X_test_tfidf)\n",
    "print(f\"score of tfidf: {logis_ml.score(X_test_tfidf, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis most import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logis_ml.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_pos_features = [bow_cv_vocab[index] for index in model.coef_[0].argsort()[::-1][:10]]\n",
    "top10_neg_features = [bow_cv_vocab[index] for index in model.coef_[0].argsort()[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top10 positive features: ['excellent', 'perfect', 'superb', 'wonderful', 'enjoyable', 'amazing', 'well worth', 'incredible', 'brilliant', 'today']\n",
      "Top10 negative features: ['worst', 'awful', 'boring', 'waste', 'disappointment', 'poorly', 'disappointing', 'poor', 'lacks', 'not worth']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top10 positive features: {top10_pos_features}\")\n",
    "print(f\"Top10 negative features: {top10_neg_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
